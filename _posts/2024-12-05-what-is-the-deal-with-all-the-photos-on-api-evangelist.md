---
published: true
layout: post
title: What Is The Deal With All The Photos On API Evangelist?
tags:
  - Images
  - Bias
  - Algorotoscope
image: >-
  https://kinlane-productions2.s3.amazonaws.com/algorotoscope-master/francis-williams-cell-tower-close.jpeg
---
The photos published alongside all of my blog posts look nothing like the other photos you see out there. They are distorted, noisy, and often fairly shocking in color and other visuals. This is by design. In a world where everyone is trying to find the right template, apply digital polish, and fit in with what the message of the day is—-my photos are the opposite of that. I get folks who won’t share my stories and have asked me what is the deal with all of the photos on API Evangelist?

All of my photos are taken by me, but then have an [Algorotoscope](https://algorithmic.rotoscope.work/) filter applied to them to reflect the bias that exists within the systems and applications we are building with APIs. [Algorotoscope](https://algorithmic.rotoscope.work/) is my project that I started in 2016 after the presidential election, using Tensorflow to apply texture transfers to the photos and videos I was taking. I wanted to learn more about developing and using machine learning (TensorFlow) models, and I was looking for a way to play around with the photos I was taking with my camera and my drone. The result is a series of ongoing ML models that are trained on a mix of political, propaganda, and other posters and art that capture my imagination.

<img src="https://kinlane-productions2.s3.amazonaws.com/algorotoscope-master/francis-williams-feminist-pioneers.jpeg">

I am deliberately stealing the essence and meaning of posters and works of art, training an ML model on them, and then applying them to many different photos I have taken over the years. The process produces a lot of noise, but every once in a while it will produce a really compelling image. The more I get to know my photos, as well as the ML models, the better they get. Some ML models apply better to far away landscape, while others apply in interesting ways to rock, stone, or maybe water. Some are just visually interesting, while others will have a combined meaning when you know that a specific ML model trained on a meaningful poster was applied to the image.

People tell me that my images likely will offend folks and are probably bad for business. I get it. I am fine with that. If y’all are fine with the existing bias that exists in the system, I am fine with you not being my reader or my customer. My mission as the API Evangelist is to make the systems and applications we build more visible for everyone involved. As long as the Internet system and the applications of it are filled with racial, gender, and class bias, my photos will look like this. It is vital that we keep the system visible and something we can have a conversation about, otherwise it will continue to grind up all of us human beings when it comes to renting or buying home, in the courtroom, via delivery apps, and the many, many, many, other ways in which APIs are infiltrating our lives and are dripping with all the bias already baked into our corporations, institutions, and government agencies.

I am regularly looking for new and more meaningful art and posters to train models on. I am always taking pictures of the physical infrastructure around us to apply my existing and new ML models on [Algorotoscope](https://algorithmic.rotoscope.work/) in new and interesting ways. If you have any ideas for images I might consider training a model on, or taking a picture to apply one of my existing models to, please let me know. I feel like this moment we are in, it is becoming increasingly important to make sure we are talking about the bias in the system--otherwise the fascism will continue to creep in and leverage the complexity and black boxiness of Internet technology to reduce all of us to daily transactions-—eventually losing ourselves in the process.